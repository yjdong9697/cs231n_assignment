{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"YAI_3rd_week.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ksbsupkJdZqZ"},"source":["## Consider the Convolutional Neural Network and answer the following questions.\n","Input shape: 32x32x3\n","10 5x5 filters, stride 1, pad 2\n","\n","(1) What is the output volume size? 32 * 32 * 10\n","\n","(2) What is the number of parameters in this layer? (Each filter has one bias) 5 * 5 * 10\n"]},{"cell_type":"markdown","metadata":{"id":"pECkovGTiNvz"},"source":["# LeNet-5 FashionMNIST Classification\n","Implement\n","*   Set hyper parameters\n","*   Call dataset from torchvision & make dataloader\n","*   Build a LeNet-5\n","*   Instantiate LeNet & define loss function and optimizer\n","*   Training\n","*   Test\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"ZZ8EsREtJuY_","executionInfo":{"status":"ok","timestamp":1628268180862,"user_tz":-540,"elapsed":844,"user":{"displayName":"‍동용훈(학부학생/공과대학 컴퓨터과학)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvtRAmaVbBH_Y7NeKgcv9JB5FJpozWSNnSjyUM=s64","userId":"00572286933900687199"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.init\n","import torch.functional as F\n","from torch.nn.modules.activation import ReLU\n","from torch.nn.modules.pooling import MaxPool2d\n","import torchvision\n","from torchvision import transforms\n","from torchvision import transforms, utils\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Set seed\n","torch.manual_seed(777)\n","\n","# Set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1glM0x2rlfp3"},"source":["# Set hyper parameters \n"]},{"cell_type":"code","metadata":{"id":"RSoRT4LQL7MO","executionInfo":{"status":"ok","timestamp":1628268180863,"user_tz":-540,"elapsed":11,"user":{"displayName":"‍동용훈(학부학생/공과대학 컴퓨터과학)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvtRAmaVbBH_Y7NeKgcv9JB5FJpozWSNnSjyUM=s64","userId":"00572286933900687199"}}},"source":["num_epochs = 10\n","batch_size = 64\n","learning_rate = 1e-3"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Opzyvz3lgHW"},"source":["# Call dataset from torchvision & make dataloader"]},{"cell_type":"code","metadata":{"id":"pRFF7sQbz3Fu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628268180863,"user_tz":-540,"elapsed":10,"user":{"displayName":"‍동용훈(학부학생/공과대학 컴퓨터과학)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvtRAmaVbBH_Y7NeKgcv9JB5FJpozWSNnSjyUM=s64","userId":"00572286933900687199"}},"outputId":"9b06964b-d224-46f9-d9c0-2f419064a999"},"source":["train_datasets = torchvision.datasets.FashionMNIST(root = \"data\", train = True, download = True, transform = transforms.ToTensor())\n","test_datasets = torchvision.datasets.FashionMNIST(root = \"data\", train = False, download = True, transform = transforms.ToTensor())\n","\n","train_loader = DataLoader(train_datasets, batch_size = batch_size, shuffle = True, drop_last = True)\n","test_loader = DataLoader(test_datasets, batch_size = batch_size, shuffle = True, drop_last = True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"vZ59BF91lg-b"},"source":["# Build a LeNet-5"]},{"cell_type":"code","metadata":{"id":"R75QeL26MOih","executionInfo":{"status":"ok","timestamp":1628268180864,"user_tz":-540,"elapsed":9,"user":{"displayName":"‍동용훈(학부학생/공과대학 컴퓨터과학)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvtRAmaVbBH_Y7NeKgcv9JB5FJpozWSNnSjyUM=s64","userId":"00572286933900687199"}}},"source":["class LeNet(nn.Module):\n","    def __init__(self):\n","        super(LeNet, self).__init__()\n","        # Input (?, 32, 32, 1) -> (?, 14, 14, 6)\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(1, 6, kernel_size = 5, stride = 1, padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)            \n","        )\n","\n","        # Input (?, 14, 14, 6) -> (?, 5, 5 , 16)\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(6, 16, kernel_size = 6, stride = 1, padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        )\n","\n","        self.fc1 = nn.Linear(5 * 5 * 16, 120, bias = True)\n","        self.fc2 = nn.Linear(120, 84, bias = True)\n","        self.fc3 = nn.Linear(84, 10, bias = True)\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = torch.flatten(out, 1)\n","        out = self.fc1(out)\n","        out = self.fc2(out)\n","        out = self.fc3(out)\n","\n","        return out"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2972V-Rnl96R"},"source":["# Instantiate LeNet & define loss function and optimizer\n"]},{"cell_type":"code","metadata":{"id":"324bWioyNWcH","executionInfo":{"status":"ok","timestamp":1628268180865,"user_tz":-540,"elapsed":9,"user":{"displayName":"‍동용훈(학부학생/공과대학 컴퓨터과학)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvtRAmaVbBH_Y7NeKgcv9JB5FJpozWSNnSjyUM=s64","userId":"00572286933900687199"}}},"source":["model = LeNet().to(device)\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4rHeiHtuqBJP"},"source":["# Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bReVubbJNhU1","executionInfo":{"status":"ok","timestamp":1628268419661,"user_tz":-540,"elapsed":238805,"user":{"displayName":"‍동용훈(학부학생/공과대학 컴퓨터과학)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvtRAmaVbBH_Y7NeKgcv9JB5FJpozWSNnSjyUM=s64","userId":"00572286933900687199"}},"outputId":"20f780ea-ab04-4b18-e679-f74f477a4bac"},"source":["total_batch = len(train_loader)\n","\n","for epoch in range(num_epochs):\n","    avg_cost = 0\n","\n","    for test in train_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\n","        # image is already size of (28x28), no reshape\n","        # label is not one-hot encoded\n","        X, Y = test\n","        X = X.to(device)\n","        Y = Y.to(device)\n","\n","        optimizer.zero_grad()\n","        hypothesis = model(X)\n","        cost = criterion(hypothesis, Y)\n","        cost.backward()\n","        optimizer.step()\n","\n","        avg_cost += cost / total_batch\n","\n","    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"],"name":"stderr"},{"output_type":"stream","text":["[Epoch:    1] cost = 0.60104084\n","[Epoch:    2] cost = 0.391909599\n","[Epoch:    3] cost = 0.338237733\n","[Epoch:    4] cost = 0.306554049\n","[Epoch:    5] cost = 0.286485434\n","[Epoch:    6] cost = 0.274062276\n","[Epoch:    7] cost = 0.262436539\n","[Epoch:    8] cost = 0.255482316\n","[Epoch:    9] cost = 0.247794136\n","[Epoch:   10] cost = 0.241150931\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i6fGudQRqI_G"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"nytmuoueN8uw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628269591935,"user_tz":-540,"elapsed":2454,"user":{"displayName":"‍동용훈(학부학생/공과대학 컴퓨터과학)","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvtRAmaVbBH_Y7NeKgcv9JB5FJpozWSNnSjyUM=s64","userId":"00572286933900687199"}},"outputId":"b0862cf4-b145-40cd-c06a-9310cbefccf0"},"source":["correct = 0\n","total = len(test_loader)\n","\n","with torch.no_grad():\n","    for data in test_loader:\n","        images, labels = data\n","        images = images.to(device)\n","        labels=labels.to(device)\n","\n","        # 학습시킨 model에 test image를 통과시켜 출력 계산\n","        outputs = model(images)\n","        # 가장 높은 값을 가지는 class를 정답으로 선택\n","        predicted = torch.argmax(outputs.data, dim = 1)\n","        correct += (predicted == labels).float().mean().item()\n","\n","print('Accuracy of the network on the 10000 test images: %.2f %%' % (\n","    100 * correct / total))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Accuracy of the network on the 10000 test images: 88.59 %\n"],"name":"stdout"}]}]}